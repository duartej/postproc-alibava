#!/usr/bin/env python
"""
Extract the list of alibava raw data files from a parent folder.
The folder should contain subdirectories with the name
of the involved sensors, and the file names follows a pre-defined
naming convention.
"""
__author__ = "Jordi Duarte-Campderros"
__credits__ = ["Jordi Duarte-Campderros"]
__version__ = "v0.1"
__maintainer__ = "Jordi Duarte-Campderros"
__email__ = "jorge.duarte.campderros@cern.ch"
__status__ = "Development"

def list_raw_files(parent_folder,verbose,beam_file=None):
    """Extract the list of alibava raw data files from a parent folder.
    The folder should contain subdirectories with the name
    of the involved sensors, and the file names follows a pre-defined
    naming convention.

    If `beam_file` is not None, the function will print the pedestal
    and calibration files (absolute paths) associated to that beam
    file; raising a RuntimeError if no pedestal and/or calibration
    file have been found, or if more than one pedestal and/or calibration
    file have been found.

    Parameters
    ----------
    parent_folder: str
        the path under where the sensors subdirectories must be localized
    verbose: bool
        whether or not to dump out more information whenever a file has
        been not included
    beam_file: str | None
        if is not None, the name (basename) of a beam-type alibava RAW
        file
    """
    import alibavaSkifftools.SPS2017TB_metadata as tb2017
    import glob
    import os

    # -- Check the sensors paths are there
    sensor_paths = [ os.path.join(parent_folder,s) for s in tb2017.sensor_names ]
    if False in filter(lambda abspath: os.path.isdir(abspath), sensor_paths):
        raise IOError("Invalid parent folder structure at '{0:s}', "\
            "missing sensors direcotories ".format(parent_folder))
    # -- 
    ###if sensor not in tb2017.sensor_names:
    ###    raise RuntimeError("Not a valid sensor name '{0}'".format(sensor))
    # -- Descend over each directory and fill a dictionary with 
    #    filename_parser instances
    sensor_files = {}
    failed = []
    for sensor in tb2017.sensor_names:
        sensor_files[sensor] = []
        beam_files =[]
        ped_cal = []
        # Find all the raw alibava data files
        for fname in glob.glob(os.path.join(os.path.join(parent_folder,sensor),"*.dat")):
            try:
                _prv = tb2017.filename_parser(fname)
            except RuntimeError:
                # The file-name format is not understood
                if fname.find("RunN") == -1:
                    print "Just ignoring '{0}'".format(fname) 
                continue
            if _prv.is_beam:
                beam_files.append(_prv)
            else:
                ped_cal.append(_prv)
        # After split between beam and auxiliary runs, associate them
        for _fb in beam_files:
            try:
                sensor_files[sensor].append(tb2017.associated_filenames(_fb,ped_cal))
            except IOError:
                # No pedestals nor calibration, skip this file
                # Store if verbose
                if verbose:
                    failed.append( (_fb,'NO CAL/PED FOUND') )
                continue
            except RuntimeError as e:
                # One pedestal or one calibration
                # Store if verbose
                if verbose:
                    failed.append( (_fb,str(e)) )
                continue
        # If a beam file is provided, check if the file is in this sensor folder
        if beam_file is not None:
            if os.path.basename(beam_file) in \
                    map(lambda x: os.path.basename(x.beam_instance.filename),sensor_files[sensor]):
                tf_inst = filter(lambda x: os.path.basename(beam_file) in \
                        os.path.basename(x.beam_instance.filename),\
                        sensor_files[sensor])[0]
                print "{0},{1}".format(tf_inst.pedestal_instance.filename,tf_inst.calibration_instance.filename)
                return
            continue
    if beam_file is not None:
        # Not found, so a raise the error
        raise RuntimeError("Not found '{0}'".format(beam_file))

    for sname,flist in sensor_files.iteritems():
        print "\033[1;34mSENSOR:\033[1;m \033[1;20m{0}\033[1;m".format(sname)
        for af in flist:
            print af
    if verbose:
        print "\033[1;33mVERBOSE: Sensors and runs with incomplete/inconsistent files\033[1;m"
        for (finst,pedcallist) in failed:
            print "{0}, run: {1}, '{2}'".format(finst.sensor_name,finst.run_number,pedcallist)

def create_steering_file(step_name,**args):
    """Create the steering file for the given step. The steering
    file will be created in the working directory. If no extra
    arguments are provided, the default will be applied

    Parameters
    ----------
    step_name: str
        the name of the step. Must correspond to a concrete class 
        of alibavaSkifftools.steering_processing.marlin_step

    ALIBAVA_INPUT_FILENAME: str, optional
        The input file name of the RAW alibava file

    See also
    --------
    alibavaSkifftools.steering_processing.marlin_step and
    their concrete classes, to get a list of valid and needed 
    template arguments
    """
    from alibavaSkifftools import steering_processing

    # create the marlin step instance
    step = steering_processing.create_marlin_step(step_name)
    # And create the steering file
    step.publish_steering_file(**args)


def merge_files(lcio_files,output_name):
    """Merge lcio files containing EORE in order to remove those 
    events. The algorithm will pick every found set of numbers, and
    will use them, previously discarding those sets common to all the names,
    to ordered based on that. 

    Parameters
    ----------
    lcio_files: list(str)
        the list of LCIO files with EORE to be merged
    output_name: str
        the name of the merged file [Default:

    Returns
    -------
    steering_filename: str
        The name of the steering file
    """
    import os
    import re
    # Mini class to deal with the sorting problem
    # A list of integers extracted from the filenames
    # are used as the handles to order the files. Assumes
    # that all the integers in the list are the same but one
    class mini_list(object):
        def __init__(self,intlist):
            """List of integers
            """
            self.intlist = intlist
        def __eq__(self,other):
            for i,val in enumerate(self.intlist):
                if val != other.intlist[i]:
                    return False
            return True

        def __lt__(self,other):
            if self == other:
                return False
            for i,val in enumerate(self.intlist):
                if val == other.intlist[i]:
                    continue
                if val > other.intlist[i]:
                    return False
            return True
        
        def __leq__(self,other):
            if self == other:
                return True
            if self < other:
                return True
            return False

    # Map of the tuples of set of numbers against their name
    discriminant_map = {}
    for fname in lcio_files:
        # Extract the subset of numbers
        discriminant_map[fname] = mini_list(map(lambda n: int(n),filter(None,re.findall(r'\d*',fname))))
    # And ordered using the integer list
    mergefiles_str =" ".join(map(lambda (k,v): k,sorted(discriminant_map.iteritems(),key=lambda (x,y): y)))

    steering_content = """<?xml version="1.0" encoding="us-ascii"?>
<!-- ?xml-stylesheet type="text/xsl" href="http://ilcsoft.desy.de/marlin/marlin.xsl"? -->
<!-- ?xml-stylesheet type="text/xsl" href="marlin.xsl"? -->

<!--Automaticaly created to gather all output files from a cluster jobs-->

<marlin xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="http://ilcsoft.desy.de/marlin/marlin.xsd">
    <execute>
      <processor name="Save"/>
      <processor name="MyEUTelUtilityPrintEventNumber"/>
   </execute>
   
   <global>
      <parameter name="LCIOInputFiles">{0} </parameter>
      <!-- Not needed, just will show a warning-->
      <!--parameter name="GearXMLFile" value="dummy_gear.xml"/-->
      <parameter name="MaxRecordNumber" value="9999999"/>
      <parameter name="SkipNEvents" value="0"/>
      <parameter name="SupressCheck" value="false"/>
      <parameter name="Verbosity" value="WARNING"/>
   </global>

   <processor name="Save" type="EUTelOutputProcessor">
       <!--Writes the current event to the specified LCIO outputfile. 
            Eventually it adds a EORE at the of the file if it was missing Needs to be the last ActiveProcessor.-->
       <!-- name of output file -->
       <parameter name="LCIOOutputFile" type="string">{1} </parameter>
       <!--write mode for output file:  WRITE_APPEND or WRITE_NEW-->
       <parameter name="LCIOWriteMode" type="string" value="WRITE_NEW"/>
       <!--Set it to true to remove intermediate EORE in merged runs-->
       <parameter name="SkipIntermediateEORE" type="bool" value="true"/>
   </processor>
   
   <processor name="MyEUTelUtilityPrintEventNumber" type="EUTelUtilityPrintEventNumber">
       <!--EUTelUtilityPrintEventNumber prints event number to screen depending on the verbosity level-->
       <!--Print event number for every n-th event-->
       <parameter name="EveryNEvents" type="int" value="5000"/>
   </processor>
</marlin>
""".format(mergefiles_str,output_name)
    stname = "merge_files_steering.xml"
    with open(stname,"w") as f:
        f.write(steering_content)
    return stname


if __name__ == '__main__':
    from argparse import ArgumentParser,Action
    from alibavaSkifftools.SPS2017TB_metadata import eospath,sensor_names
    from alibavaSkifftools.steering_processing import _ARGUMENTS as template_args

    # Helper class to allow list sensor names (without introducing
    # the positional arguments
    class SensorNamesAction(Action):
        def __init__(self,option_strings,dest,default=False,required=False,help=None):
            super(SensorNamesAction, self).__init__(
                    option_strings=option_strings,
                    dest=dest,
                    nargs=0,
                    const=True,
                    default=default,
                    required=required,
                    help=help)

        def __call__(self, parser, namespace, values, option_string=None):
            print "\033[1;34mAvailable sensor names:\033[1;m"
            for sensor in sensor_names:
                print " - {0}".format(sensor)
            parser.exit()
    
    # Helper class to allow list steering steps (without introducing
    # the positional arguments
    class StepNamesAction(Action):
        def __init__(self,option_strings,dest,default=False,required=False,help=None):
            super(StepNamesAction, self).__init__(
                    option_strings=option_strings,
                    dest=dest,
                    nargs=0,
                    const=True,
                    default=default,
                    required=required,
                    help=help)

        def __call__(self, parser, namespace, values, option_string=None):
            from alibavaSkifftools.steering_processing import available_steps as _steps
            print "\033[1;34mAvailable steps:\033[1;m"
            for step in _steps:
                print " - \033[1;29m{0}\033[1;m: {1}".format(step.__name__,step.get_description())
            parser.exit()
    
    mesdsc="A suite of tools to deal with the ALIBAVA (and EUTelescope)"
    mesdsc+=" data output. Get the description of each subcommand with"
    mesdsc+=" help option."
    parser = ArgumentParser(prog='open_sesame',description=mesdsc)
    
    # Sub-command parsers
    subparsers = parser.add_subparsers(title='subcommands',
            description='valid subcommands', 
            help='additional help')
    
    # -- Subparser: list data sensor, test beam data associated to their
    #               respective pedestal and calibration files 
    usage_ld  = "Extract the list of alibava raw data files from a parent folder. "
    usage_ld += "The folder should contain subdirectories with the name of the"
    usage_ld += " involved sensors; and the file names follow a pre-defined naming "
    usage_ld += "convention. If `--beam-filename` option is used, the pedestal,calibration"
    usage_ld += " files will be printed instead."
    
    ld_parser = subparsers.add_parser("list_files",description=usage_ld)
    ld_parser.add_argument('parent_folder',help="The parent folder to start"\
            " to search down [Default: see SPS2017TB_metadata.eospath]")
    ld_parser.add_argument('-b','--beam-filename',action='store',dest='beam_file',\
            help="The file name of the beam-type file to obtain the pedestal and calibration"\
            " files associated to it")
    ld_parser.add_argument('-p','--print-available-sensors',dest="available_sensors",\
            action=SensorNamesAction,help='Just print the available'\
            ' sensor names')
    ld_parser.add_argument('-v',dest="verbose",action='store_true',help="Show the list of ignored run numbers"\
            " because of any problem")
    ld_parser.set_defaults(which='list_files',parent_folder=eospath,beam_file=None,ignore_runs=[])
    
    # -- Subparser: steering file creator for the ALIBAVA/TELESCOPE data 
    #               reconstruction
    usage_st  = "Build the needed steering files to run a given step of the marlin"
    usage_st += " framework reconstruction for the ALIBAVA or TELESCOPE data. Note"
    usage_st += " that the steering file is created in the working directory."
    usage_st += " All the available options but the `--print-availble-steps` are"
    usage_st += " directly related with the relevant steering file (see the"
    usage_st += " steering files under `steering_files` directory "

    st_parser = subparsers.add_parser("steering",description=usage_st)
    st_parser.add_argument('step',help="The step name to create the steering file"\
            " [See `--print-available-steps` option] ")
    st_parser.add_argument('--alibava-input-filename',dest="ALIBAVA_INPUT_FILENAME",action='store',\
            help=template_args['ALIBAVA_INPUT_FILENAME'])
    st_parser.add_argument('--telescope-input-filename',dest="TELESCOPE_INPUT_FILENAME",action='store',\
            help=template_args['TELESCOPE_INPUT_FILENAME'])
    st_parser.add_argument('--input-filename',dest="INPUT_FILENAMES",action='store',\
            help=template_args['INPUT_FILENAMES'])
    st_parser.add_argument('--active-channels',dest="ACTIVE_CHANNELS",action='store',\
            help=template_args['ACTIVE_CHANNELS'])
    st_parser.add_argument('--enable-automasking',dest="ENABLE_AUTOMASKING",action='store',\
            help=template_args['ENABLE_AUTOMASKING'])
    st_parser.add_argument('--criterium-automasking',dest="CRITERIUM_AUTOMASKING",action='store',\
            help=template_args['CRITERIUM_AUTOMASKING'])
    st_parser.add_argument('--run-number',dest="RUN_NUMBER",action='store',\
            help=template_args['RUN_NUMBER'])
    st_parser.add_argument('--root-filename',dest="ROOT_FILENAME",action='store',\
            help=template_args['ROOT_FILENAME'])
    st_parser.add_argument('--gear-file',dest="GEAR_FILE",action='store',\
            help=template_args['GEAR_FILE'])
    st_parser.add_argument('--output-filename',dest="OUTPUT_FILENAME",action='store',\
            help=template_args['OUTPUT_FILENAME'])
    st_parser.add_argument('--pedestal-output-filename',dest="PEDESTAL_OUTPUT_FILENAME",action='store',\
            help=template_args['PEDESTAL_OUTPUT_FILENAME'])
    st_parser.add_argument('--pedestal-input-filename',dest="PEDESTAL_INPUT_FILENAME",action='store',\
            help=template_args['PEDESTAL_INPUT_FILENAME']+" (Related with --pedestal-ouput-filename)")
    st_parser.add_argument('--histo-xmax',dest="MAXADC",action='store',\
            help=template_args['MAXADC'])
    st_parser.add_argument('--histo-xmin',dest="MINADC",action='store',\
            help=template_args['MINADC'])
    st_parser.add_argument('--histo-nbins',dest="NBINS",action='store',\
            help=template_args['NBINS'])
    st_parser.add_argument('--calibration-output-filename',dest="CALIBRATION_OUTPUT_FILENAME",action='store',\
            help=template_args['CALIBRATION_OUTPUT_FILENAME'])
    st_parser.add_argument('--calibration-input-filename',dest="CALIBRATION_INPUT_FILENAME",action='store',\
            help=template_args['CALIBRATION_INPUT_FILENAME'])
    st_parser.add_argument('--timecut-min',dest="TIMECUT_MIN",action='store',\
            help=template_args['TIMECUT_MIN'])
    st_parser.add_argument('--timecut-max',dest="TIMECUT_MAX",action='store',\
            help=template_args['TIMECUT_MAX'])
    st_parser.add_argument('--cmmdcut-min',dest="CMMDCUT_MIN",action='store',\
            help=template_args['CMMDCUT_MIN'])
    st_parser.add_argument('--cmmdcut-max',dest="CMMDCUT_MAX",action='store',\
            help=template_args['CMMDCUT_MAX'])
    st_parser.add_argument('--snrcut-seed',dest="SNRCUT_SEED",action='store',\
            help=template_args['SNRCUT_SEED'])
    st_parser.add_argument('--snrcut-neighbour',dest="SNRCUT_NGB",action='store',\
            help=template_args['SNRCUT_NGB'])
    st_parser.add_argument('--signal-polarity',dest="SIGNAL_POLARITY",action='store',\
            help=template_args['SIGNAL_POLARITY'])
    st_parser.add_argument('--sensor-id-starts-at',dest="SENSORID_STARTS",action='store',\
            help=template_args['SENSORID_STARTS'])
    st_parser.add_argument('--prealignment-dump-gear',dest='PREALIGN_DUMP_GEAR',action='store_true',\
            help=template_args['PREALIGN_DUMP_GEAR'])
    st_parser.add_argument('-p','--print-available-steps',dest="available_steps",\
            action=StepNamesAction,help='Just print the available step names')
    st_parser.set_defaults(which='steering',ignore_runs=[])
    
    # -- Subparser: simple file merger when dealing with EORE extra events
    usage_fm  = "Create the steering file to be used to merge a collection "
    usage_fm += "of slcio files containing the 'End of Run Event' (EORE). "
    usage_fm += "The usual method (lcio_merge_files) does not take into "
    usage_fm += "account that last event added by the EUTelescope processors "
    usage_fm += "and it will result in a lost of synchronization. Using the "
    usage_fm += "created steering file here, the EOREs will be removed and "
    usage_fm += "the events merged properly"
    
    fm_parser = subparsers.add_parser("merge_eore",description=usage_fm)
    fm_parser.add_argument('lcio_files',nargs="+",help="The bunch of LCIO files containing"\
            " the EORE 'End of Run Event' added by some EUTelescope processors")
    fm_parser.add_argument('-o','--output',dest='output',action='store',\
            help="The merged file [Default: merged_output.slcio")
    fm_parser.set_defaults(which='merge_eore',output='merged_output.slcio')

    args = parser.parse_args()
    
    if args.which == 'list_files':
        list_raw_files(args.parent_folder,args.verbose,args.beam_file)
    elif args.which == 'steering':
        valid_args = template_args.keys()
        # Get the list of arguments related with the steering file template
        # which are filled
        the_args = dict(filter(lambda (k,v): k in valid_args and v is not None,args.__dict__.iteritems()))
        # arguments in the template steering files
        create_steering_file(args.step,**the_args)
    elif args.which == 'merge_eore':
        steering_filename=merge_files(args.lcio_files,args.output)
        print "\033[1;34mTo create the merged file, run: \033[1;m\n"\
                " \033[1;29mMarlin {0}\033[1;m".format(steering_filename)

